{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "701cc30f-6f7e-4d07-ac01-92aa5225d10f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping segment 166 due to insufficient length: 0 samples\n",
      "Skipping segment 167 due to insufficient length: 0 samples\n",
      "Skipping segment 304 due to insufficient length: 0 samples\n",
      "Skipping segment 401 due to insufficient length: 0 samples\n",
      "Skipping segment 466 due to insufficient length: 0 samples\n",
      "Skipping segment 467 due to insufficient length: 0 samples\n",
      "Skipping segment 468 due to insufficient length: 0 samples\n",
      "Skipping segment 469 due to insufficient length: 0 samples\n",
      "Skipping segment 470 due to insufficient length: 0 samples\n",
      "Skipping segment 471 due to insufficient length: 0 samples\n",
      "Skipping segment 472 due to insufficient length: 0 samples\n",
      "Skipping segment 473 due to insufficient length: 0 samples\n",
      "Skipping segment 474 due to insufficient length: 0 samples\n",
      "Skipping segment 475 due to insufficient length: 0 samples\n",
      "Skipping segment 476 due to insufficient length: 0 samples\n",
      "Skipping segment 477 due to insufficient length: 0 samples\n",
      "Skipping segment 478 due to insufficient length: 0 samples\n",
      "Skipping segment 479 due to insufficient length: 0 samples\n",
      "Skipping segment 480 due to insufficient length: 0 samples\n",
      "Skipping segment 481 due to insufficient length: 0 samples\n",
      "Skipping segment 482 due to insufficient length: 0 samples\n",
      "Skipping segment 483 due to insufficient length: 0 samples\n",
      "Skipping segment 484 due to insufficient length: 0 samples\n",
      "Skipping segment 485 due to insufficient length: 0 samples\n",
      "Skipping segment 486 due to insufficient length: 0 samples\n",
      "Skipping segment 487 due to insufficient length: 0 samples\n",
      "Skipping segment 488 due to insufficient length: 0 samples\n",
      "Skipping segment 489 due to insufficient length: 0 samples\n",
      "Skipping segment 490 due to insufficient length: 0 samples\n",
      "Skipping segment 491 due to insufficient length: 0 samples\n",
      "Skipping segment 525 due to insufficient length: 0 samples\n",
      "Skipping segment 526 due to insufficient length: 0 samples\n",
      "Skipping segment 527 due to insufficient length: 0 samples\n",
      "Skipping segment 528 due to insufficient length: 0 samples\n",
      "Skipping segment 529 due to insufficient length: 0 samples\n",
      "Skipping segment 530 due to insufficient length: 0 samples\n",
      "Skipping segment 531 due to insufficient length: 0 samples\n",
      "Skipping segment 532 due to insufficient length: 0 samples\n",
      "Skipping segment 533 due to insufficient length: 0 samples\n",
      "Skipping segment 534 due to insufficient length: 0 samples\n",
      "Skipping segment 535 due to insufficient length: 0 samples\n",
      "Skipping segment 536 due to insufficient length: 0 samples\n",
      "Skipping segment 537 due to insufficient length: 0 samples\n",
      "Skipping segment 538 due to insufficient length: 0 samples\n",
      "Skipping segment 539 due to insufficient length: 0 samples\n",
      "Skipping segment 540 due to insufficient length: 0 samples\n",
      "Skipping segment 541 due to insufficient length: 0 samples\n",
      "Skipping segment 542 due to insufficient length: 0 samples\n",
      "Skipping segment 543 due to insufficient length: 0 samples\n",
      "Skipping segment 544 due to insufficient length: 0 samples\n",
      "Skipping segment 654 due to insufficient length: 0 samples\n",
      "Skipping segment 655 due to insufficient length: 0 samples\n",
      "Skipping segment 656 due to insufficient length: 0 samples\n",
      "Skipping segment 657 due to insufficient length: 0 samples\n",
      "Skipping segment 658 due to insufficient length: 0 samples\n",
      "Skipping segment 659 due to insufficient length: 0 samples\n",
      "Skipping segment 660 due to insufficient length: 0 samples\n",
      "Skipping segment 661 due to insufficient length: 0 samples\n",
      "Skipping segment 662 due to insufficient length: 0 samples\n",
      "Skipping segment 663 due to insufficient length: 0 samples\n",
      "Skipping segment 664 due to insufficient length: 0 samples\n",
      "Skipping segment 665 due to insufficient length: 0 samples\n",
      "Skipping segment 666 due to insufficient length: 0 samples\n",
      "Skipping segment 667 due to insufficient length: 0 samples\n",
      "Skipping segment 714 due to insufficient length: 0 samples\n",
      "Skipping segment 715 due to insufficient length: 0 samples\n",
      "Skipping segment 728 due to insufficient length: 0 samples\n",
      "Skipping segment 1140 due to insufficient length: 0 samples\n",
      "Skipping segment 1141 due to insufficient length: 0 samples\n",
      "Skipping segment 1142 due to insufficient length: 0 samples\n",
      "Skipping segment 1143 due to insufficient length: 0 samples\n",
      "Skipping segment 1199 due to insufficient length: 0 samples\n",
      "Skipping segment 1200 due to insufficient length: 0 samples\n",
      "Skipping segment 1201 due to insufficient length: 0 samples\n",
      "Skipping segment 1202 due to insufficient length: 0 samples\n",
      "Skipping segment 1203 due to insufficient length: 0 samples\n",
      "Skipping segment 1213 due to insufficient length: 0 samples\n",
      "Skipping segment 1214 due to insufficient length: 0 samples\n",
      "Skipping segment 1215 due to insufficient length: 0 samples\n",
      "Skipping segment 1216 due to insufficient length: 0 samples\n",
      "Skipping segment 1258 due to insufficient length: 0 samples\n",
      "Skipping segment 1259 due to insufficient length: 0 samples\n",
      "Skipping segment 1260 due to insufficient length: 0 samples\n",
      "Skipping segment 1261 due to insufficient length: 0 samples\n",
      "Skipping segment 1262 due to insufficient length: 0 samples\n",
      "Skipping segment 1263 due to insufficient length: 0 samples\n",
      "Skipping segment 1264 due to insufficient length: 0 samples\n",
      "Skipping segment 1265 due to insufficient length: 0 samples\n",
      "Skipping segment 1266 due to insufficient length: 0 samples\n",
      "Skipping segment 1267 due to insufficient length: 0 samples\n",
      "Skipping segment 1268 due to insufficient length: 0 samples\n",
      "Skipping segment 1269 due to insufficient length: 0 samples\n",
      "Skipping segment 1317 due to insufficient length: 0 samples\n",
      "Skipping segment 1318 due to insufficient length: 0 samples\n",
      "Skipping segment 1319 due to insufficient length: 0 samples\n",
      "Skipping segment 1320 due to insufficient length: 0 samples\n",
      "Skipping segment 1321 due to insufficient length: 0 samples\n",
      "Skipping segment 1322 due to insufficient length: 0 samples\n",
      "Skipping segment 1323 due to insufficient length: 0 samples\n",
      "Skipping segment 1324 due to insufficient length: 0 samples\n",
      "Skipping segment 1325 due to insufficient length: 0 samples\n",
      "Skipping segment 1326 due to insufficient length: 0 samples\n",
      "Skipping segment 1327 due to insufficient length: 0 samples\n",
      "Skipping segment 1417 due to insufficient length: 0 samples\n",
      "Skipping segment 1418 due to insufficient length: 0 samples\n",
      "Skipping segment 1419 due to insufficient length: 0 samples\n",
      "Skipping segment 1420 due to insufficient length: 0 samples\n",
      "Skipping segment 1421 due to insufficient length: 0 samples\n",
      "Skipping segment 1422 due to insufficient length: 0 samples\n",
      "Total segments skipped: 109 out of 1423\n",
      "Class distribution:\n",
      "Class 0 (Field pause): 21 samples\n",
      "Class 1 (Filled pause): 1293 samples\n",
      "\n",
      "1-shot dataset class distribution:\n",
      "Class 0 (Field pause): 1 samples\n",
      "Class 1 (Filled pause): 1 samples\n",
      "\n",
      "3-shot dataset class distribution:\n",
      "Class 0 (Field pause): 3 samples\n",
      "Class 1 (Filled pause): 3 samples\n",
      "\n",
      "5-shot dataset class distribution:\n",
      "Class 0 (Field pause): 5 samples\n",
      "Class 1 (Filled pause): 5 samples\n",
      "\n",
      "10-shot dataset class distribution:\n",
      "Class 0 (Field pause): 10 samples\n",
      "Class 1 (Filled pause): 10 samples\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from collections import Counter\n",
    "\n",
    "# Create directories for saving results\n",
    "os.makedirs('results/tables', exist_ok=True)\n",
    "os.makedirs('results/plots', exist_ok=True)\n",
    "\n",
    "# Paths to JSON and audio files\n",
    "json_folder = 'JSON'\n",
    "audio_folder = './output/cleaned_wav_files'\n",
    "\n",
    "# Match audio and JSON files\n",
    "json_files = {os.path.splitext(f)[0]: os.path.join(json_folder, f) for f in os.listdir(json_folder) if f.endswith('.json')}\n",
    "audio_files = {os.path.splitext(f)[0]: os.path.join(audio_folder, f) for f in os.listdir(audio_folder) if f.endswith(('.wav', '.m4a', '.mp3'))}\n",
    "matched_files = {name: (json_files[name], audio_files[name]) for name in json_files if name in audio_files}\n",
    "\n",
    "# Function to load annotations from a JSON file\n",
    "def load_annotations(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotations = []\n",
    "    for item in data[0]['annotations'][0]['result']:\n",
    "        if item['type'] == 'labels':\n",
    "            start = item['value']['start']\n",
    "            end = item['value']['end']\n",
    "            label = item['value']['labels'][0]\n",
    "            annotations.append((start, end, label))\n",
    "    return annotations\n",
    "\n",
    "# Function to extract audio segments based on annotations\n",
    "def extract_audio_segments(audio_file, annotations, sr=16000):\n",
    "    y, _ = librosa.load(audio_file, sr=sr)\n",
    "    segments = []\n",
    "    for start, end, label in annotations:\n",
    "        segment = y[int(start * sr):int(end * sr)]\n",
    "        segments.append((segment, label))\n",
    "    return segments\n",
    "\n",
    "# Function to extract features (MFCC) from audio segments with improved handling of short segments\n",
    "def extract_features(segments, n_mfcc=40, max_length=300, min_segment_length=512):\n",
    "    features, labels = [], []\n",
    "    skipped_segments = 0\n",
    "    \n",
    "    for i, (segment, label) in enumerate(segments):\n",
    "        try:\n",
    "            # Check if the segment is too short for any FFT processing\n",
    "            if len(segment) < min_segment_length:\n",
    "                print(f\"Skipping segment {i} due to insufficient length: {len(segment)} samples\")\n",
    "                skipped_segments += 1\n",
    "                continue\n",
    "                \n",
    "            # For very short segments, use a smaller n_fft and hop_length\n",
    "            if len(segment) < 2048:\n",
    "                n_fft = 512\n",
    "                hop_length = 128\n",
    "            else:\n",
    "                n_fft = 2048\n",
    "                hop_length = 512\n",
    "                \n",
    "            # Extract MFCC features with adjusted parameters\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=segment, \n",
    "                sr=16000, \n",
    "                n_mfcc=n_mfcc, \n",
    "                n_fft=n_fft,\n",
    "                hop_length=hop_length\n",
    "            )\n",
    "            \n",
    "            # Handle variable lengths (pad if short, truncate if long)\n",
    "            if mfcc.shape[1] < max_length:\n",
    "                padded_mfcc = np.pad(mfcc, ((0, 0), (0, max_length - mfcc.shape[1])), mode='constant')\n",
    "            else:\n",
    "                padded_mfcc = mfcc[:, :max_length]\n",
    "                \n",
    "            # Append features and labels\n",
    "            features.append(padded_mfcc.T)\n",
    "            labels.append(0 if label == 'Field pause' else 1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment {i}: {e}\")\n",
    "            skipped_segments += 1\n",
    "    \n",
    "    print(f\"Total segments skipped: {skipped_segments} out of {len(segments)}\")\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Load the dataset\n",
    "dataset = []\n",
    "files_loaded = []\n",
    "\n",
    "for name, (json_path, audio_path) in matched_files.items():\n",
    "    annotations = load_annotations(json_path)\n",
    "    if len(annotations) != 0:\n",
    "        files_loaded.append(json_path)\n",
    "        audio_segments = extract_audio_segments(audio_path, annotations)\n",
    "        dataset.extend(audio_segments)\n",
    "\n",
    "# Extract features with improved handling of short segments\n",
    "X, y = extract_features(dataset, min_segment_length=256)  # Lowered minimum segment length\n",
    "\n",
    "# Display class distribution\n",
    "print(\"Class distribution:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"Class {label} ({'Field pause' if label == 0 else 'Filled pause'}): {count} samples\")\n",
    "\n",
    "# Plot class distribution\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.countplot(x=y)\n",
    "plt.title('Class Distribution in Dataset')\n",
    "plt.xlabel('Class (0: Field pause, 1: Filled pause)')\n",
    "plt.ylabel('Count')\n",
    "plt.savefig('results/plots/class_distribution.png')\n",
    "plt.close()\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Create few-shot learning datasets\n",
    "def create_few_shot_dataset(X, y, n_shots=5, random_state=42):\n",
    "    \"\"\"\n",
    "    Create a few-shot learning dataset with n examples per class\n",
    "    \"\"\"\n",
    "    np.random.seed(random_state)\n",
    "    \n",
    "    # Find indices for each class\n",
    "    unique_labels = np.unique(y)\n",
    "    few_shot_indices = []\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        indices = np.where(y == label)[0]\n",
    "        n_available = len(indices)\n",
    "        selected_n = min(n_shots, n_available)\n",
    "        \n",
    "        if selected_n < n_shots:\n",
    "            print(f\"Warning: Only {selected_n} samples available for class {label}\")\n",
    "        \n",
    "        selected = np.random.choice(indices, selected_n, replace=False)\n",
    "        few_shot_indices.extend(selected)\n",
    "    \n",
    "    return X[few_shot_indices], y[few_shot_indices]\n",
    "\n",
    "# Prepare few-shot datasets with different numbers of shots\n",
    "few_shot_configs = [1, 3, 5, 10]\n",
    "few_shot_datasets = {}\n",
    "\n",
    "for n_shots in few_shot_configs:\n",
    "    X_few, y_few = create_few_shot_dataset(X_train, y_train, n_shots=n_shots)\n",
    "    few_shot_datasets[n_shots] = (X_few, y_few)\n",
    "    \n",
    "    # Display class distribution for each few-shot dataset\n",
    "    print(f\"\\n{n_shots}-shot dataset class distribution:\")\n",
    "    unique, counts = np.unique(y_few, return_counts=True)\n",
    "    for label, count in zip(unique, counts):\n",
    "        print(f\"Class {label} ({'Field pause' if label == 0 else 'Filled pause'}): {count} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3b8216-4f8a-4144-a397-e4a5723bd864",
   "metadata": {},
   "source": [
    "# 2. Balanced Sampling Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52864914-6948-4670-92b2-ca6d303389a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified balanced training setup for extreme imbalance\n",
    "def create_balanced_datasets(X_train, y_train, X_test, y_test):\n",
    "    \"\"\"Create balanced datasets for training using different techniques\"\"\"\n",
    "    \n",
    "    # Calculate class distribution\n",
    "    class_counts = Counter(y_train)\n",
    "    minority_class = min(class_counts, key=class_counts.get)\n",
    "    minority_count = class_counts[minority_class]\n",
    "    \n",
    "    print(f\"\\nCreating balanced datasets from {len(y_train)} samples\")\n",
    "    print(f\"Original class distribution: {dict(class_counts)}\")\n",
    "    \n",
    "    balanced_datasets = {}\n",
    "    \n",
    "    # 1. Random Undersampling - use all minority samples, randomly select majority samples\n",
    "    majority_indices = np.where(y_train != minority_class)[0]\n",
    "    minority_indices = np.where(y_train == minority_class)[0]\n",
    "    \n",
    "    # Randomly select majority samples equal to minority count * factor\n",
    "    undersampling_factor = 2  # Use 2x minority samples from majority class\n",
    "    selected_majority = np.random.choice(\n",
    "        majority_indices, \n",
    "        size=min(minority_count * undersampling_factor, len(majority_indices)),\n",
    "        replace=False\n",
    "    )\n",
    "    \n",
    "    # Combine indices and create balanced dataset\n",
    "    balanced_indices = np.concatenate([minority_indices, selected_majority])\n",
    "    X_balanced = X_train[balanced_indices]\n",
    "    y_balanced = y_train[balanced_indices]\n",
    "    \n",
    "    balanced_datasets['undersampled'] = (X_balanced, y_balanced)\n",
    "    \n",
    "    # Print the new distribution\n",
    "    print(f\"Undersampled dataset: {len(X_balanced)} samples, distribution: {dict(Counter(y_balanced))}\")\n",
    "    \n",
    "    # 2. Create few-shot learning datasets\n",
    "    minority_shots = min(minority_count, 20)  # Cap at 20 samples\n",
    "    shot_configs = [1, 3, 5, 10, minority_shots]\n",
    "    \n",
    "    for n_shots in shot_configs:\n",
    "        if n_shots <= minority_count:\n",
    "            X_few, y_few = create_few_shot_dataset(X_train, y_train, n_shots)\n",
    "            balanced_datasets[f'{n_shots}-shot'] = (X_few, y_few)\n",
    "            print(f\"{n_shots}-shot dataset: {len(X_few)} samples, distribution: {dict(Counter(y_few))}\")\n",
    "    \n",
    "    return balanced_datasets\n",
    "\n",
    "# Function to balance predictions based on class probabilities\n",
    "def balanced_predict(model, X, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Make predictions with adjusted threshold to account for class imbalance\n",
    "    \"\"\"\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        y_prob = model.predict_proba(X)[:, 1]\n",
    "        y_pred = (y_prob > threshold).astype(int)\n",
    "    else:\n",
    "        # If model doesn't support probability\n",
    "        y_pred = model.predict(X)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270316c2-dc80-41aa-bb90-32549d96832c",
   "metadata": {},
   "source": [
    "# 3. Specialized Models for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65a7491e-d9d5-44fc-9f46-064741827e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier, RUSBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "def train_balanced_models(X_train, y_train, X_test, y_test, shot_config=\"full\"):\n",
    "    \"\"\"Train models specifically designed for imbalanced datasets\"\"\"\n",
    "    \n",
    "    # Reshape data\n",
    "    X_train_2d = X_train.reshape(X_train.shape[0], -1)\n",
    "    X_test_2d = X_test.reshape(X_test.shape[0], -1)\n",
    "    \n",
    "    # 1. Balanced Random Forest\n",
    "    print(f\"\\nTraining Balanced Random Forest ({shot_config})...\")\n",
    "    brf = BalancedRandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        replacement=True,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    brf.fit(X_train_2d, y_train)\n",
    "    results = evaluate_model(brf, X_test_2d, y_test, 'BalancedRF', shot_config)\n",
    "    all_results.append(results)\n",
    "    plot_confusion_matrix(results['confusion_matrix'], 'BalancedRF', shot_config)\n",
    "    \n",
    "    # 2. RUSBoost\n",
    "    print(f\"\\nTraining RUSBoost ({shot_config})...\")\n",
    "    rusboost = RUSBoostClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    rusboost.fit(X_train_2d, y_train)\n",
    "    results = evaluate_model(rusboost, X_test_2d, y_test, 'RUSBoost', shot_config)\n",
    "    all_results.append(results)\n",
    "    plot_confusion_matrix(results['confusion_matrix'], 'RUSBoost', shot_config)\n",
    "    \n",
    "    # 3. Cost-sensitive SVM\n",
    "    print(f\"\\nTraining Cost-sensitive SVM ({shot_config})...\")\n",
    "    \n",
    "    # Calculate class weights inversely proportional to class frequencies\n",
    "    class_counts = Counter(y_train)\n",
    "    n_samples = len(y_train)\n",
    "    class_weights = {\n",
    "        c: n_samples / (len(class_counts) * count)\n",
    "        for c, count in class_counts.items()\n",
    "    }\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_2d)\n",
    "    X_test_scaled = scaler.transform(X_test_2d)\n",
    "    \n",
    "    # Train weighted SVM\n",
    "    svm_weighted = SVC(\n",
    "        kernel='rbf',\n",
    "        class_weight=class_weights,\n",
    "        probability=True,\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    svm_weighted.fit(X_train_scaled, y_train)\n",
    "    results = evaluate_model(svm_weighted, X_test_scaled, y_test, 'WeightedSVM', shot_config)\n",
    "    all_results.append(results)\n",
    "    plot_confusion_matrix(results['confusion_matrix'], 'WeightedSVM', shot_config)\n",
    "    \n",
    "    # 4. XGBoost with scale_pos_weight\n",
    "    print(f\"\\nTraining Weighted XGBoost ({shot_config})...\")\n",
    "    \n",
    "    # Calculate positive class weight\n",
    "    scale_pos_weight = class_counts[0] / class_counts[1] if 1 in class_counts else 1.0\n",
    "    \n",
    "    xgb_weighted = xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        learning_rate=0.1,\n",
    "        max_depth=3,\n",
    "        scale_pos_weight=scale_pos_weight,\n",
    "        random_state=42,\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss'\n",
    "    )\n",
    "    \n",
    "    xgb_weighted.fit(X_train_2d, y_train)\n",
    "    results = evaluate_model(xgb_weighted, X_test_2d, y_test, 'WeightedXGB', shot_config)\n",
    "    all_results.append(results)\n",
    "    plot_confusion_matrix(results['confusion_matrix'], 'WeightedXGB', shot_config)\n",
    "    \n",
    "    return {\n",
    "        'BalancedRF': brf,\n",
    "        'RUSBoost': rusboost,\n",
    "        'WeightedSVM': {'model': svm_weighted, 'scaler': scaler},\n",
    "        'WeightedXGB': xgb_weighted\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9cd438-3ffc-4812-bf4d-ac3dff97ebe1",
   "metadata": {},
   "source": [
    "# 4. Modified Evaluation Metrics for Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "382356e0-0672-4585-85bb-bd6861b989bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score, f1_score\n",
    "\n",
    "def evaluate_model_imbalanced(model, X_test, y_test, model_name, shot_config=\"full\"):\n",
    "    \"\"\"\n",
    "    Evaluate a model with metrics suitable for imbalanced datasets\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Reshape data if needed\n",
    "    X_test_reshaped = X_test.reshape(X_test.shape[0], -1) if len(X_test.shape) > 2 else X_test\n",
    "    \n",
    "    # For models that return probabilities\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        y_prob = model.predict_proba(X_test_reshaped)[:, 1]\n",
    "        \n",
    "        # Calculate precision-recall curve\n",
    "        precision, recall, thresholds = precision_recall_curve(y_test, y_prob)\n",
    "        \n",
    "        # Find threshold that maximizes F1 score\n",
    "        f1_scores = [f1_score(y_test, (y_prob >= t).astype(int)) for t in thresholds]\n",
    "        best_threshold_idx = np.argmax(f1_scores[:-1])  # last element has no threshold\n",
    "        best_threshold = thresholds[best_threshold_idx]\n",
    "        \n",
    "        # Calculate predictions with optimal threshold\n",
    "        y_pred = (y_prob >= best_threshold).astype(int)\n",
    "        \n",
    "        # Calculate AUC-PR (Area Under Precision-Recall Curve)\n",
    "        average_precision = average_precision_score(y_test, y_prob)\n",
    "    else:\n",
    "        # If no probability predictions available\n",
    "        y_pred = model.predict(X_test_reshaped)\n",
    "        average_precision = None\n",
    "        best_threshold = None\n",
    "    \n",
    "    # Calculate standard metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    # Execution time\n",
    "    execution_time = time.time() - start_time\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\n{model_name} ({shot_config}) Results:\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "    if average_precision:\n",
    "        print(f\"Average Precision (AP): {average_precision:.4f}\")\n",
    "    if best_threshold:\n",
    "        print(f\"Best threshold: {best_threshold:.4f}\")\n",
    "    print(f\"Execution Time: {execution_time:.2f} seconds\")\n",
    "    \n",
    "    # Plot precision-recall curve if available\n",
    "    if average_precision:\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.step(recall, precision, where='post')\n",
    "        plt.xlabel('Recall')\n",
    "        plt.ylabel('Precision')\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title(f'Precision-Recall curve: AP={average_precision:.3f} ({model_name})')\n",
    "        plt.savefig(f'results/plots/pr_curve_{model_name}_{shot_config}.png')\n",
    "        plt.close()\n",
    "    \n",
    "    # Return results\n",
    "    results = {\n",
    "        'model_name': f\"{model_name}_{shot_config}\",\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1_score': f1,\n",
    "        'average_precision': average_precision,\n",
    "        'best_threshold': best_threshold,\n",
    "        'confusion_matrix': cm,\n",
    "        'execution_time': execution_time,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba23116-16c8-466f-8686-1c96c62bb6c9",
   "metadata": {},
   "source": [
    "# 5. Multiple Test Sets Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "61266749-5ce9-4dde-a5ea-fcd2504afc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def create_multiple_test_sets(X, y, n_splits=5):\n",
    "    \"\"\"Create multiple stratified train-test splits for robust evaluation\"\"\"\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    test_sets = []\n",
    "    \n",
    "    for train_idx, test_idx in skf.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        test_sets.append((X_train, y_train, X_test, y_test))\n",
    "    \n",
    "    return test_sets\n",
    "\n",
    "def cross_validation_evaluation(model_trainer, X, y, model_name, n_splits=5):\n",
    "    \"\"\"Evaluate model with cross-validation for more robust results\"\"\"\n",
    "    \n",
    "    test_sets = create_multiple_test_sets(X, y, n_splits)\n",
    "    all_fold_results = []\n",
    "    \n",
    "    for fold, (X_train, y_train, X_test, y_test) in enumerate(test_sets):\n",
    "        print(f\"\\nTraining {model_name} - Fold {fold+1}/{n_splits}\")\n",
    "        model = model_trainer(X_train, y_train)\n",
    "        \n",
    "        # Reshape for evaluation\n",
    "        X_test_reshaped = X_test.reshape(X_test.shape[0], -1) if len(X_test.shape) > 2 else X_test\n",
    "        \n",
    "        # Evaluate\n",
    "        results = evaluate_model_imbalanced(model, X_test_reshaped, y_test, f\"{model_name}_fold{fold+1}\")\n",
    "        all_fold_results.append(results)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_metrics = {\n",
    "        'accuracy': np.mean([r['accuracy'] for r in all_fold_results]),\n",
    "        'precision': np.mean([r['precision'] for r in all_fold_results]),\n",
    "        'recall': np.mean([r['recall'] for r in all_fold_results]),\n",
    "        'f1_score': np.mean([r['f1_score'] for r in all_fold_results]),\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name} - Average Cross-Validation Results:\")\n",
    "    print(f\"Accuracy: {avg_metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {avg_metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {avg_metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {avg_metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    return avg_metrics, all_fold_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58cf20c-7825-4094-965f-4e9054272611",
   "metadata": {},
   "source": [
    "# 6. Main Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64769a2e-86d7-46bf-92c7-99aea4e69f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting filled pause detection model evaluation with imbalanced data handling...\n",
      "\n",
      "Data distribution analysis:\n",
      "Class 0 (Field pause): 21 samples (1.60%)\n",
      "Class 1 (Filled pause): 1293 samples (98.40%)\n",
      "\n",
      "Creating balanced datasets from 1051 samples\n",
      "Original class distribution: {1: 1034, 0: 17}\n",
      "Undersampled dataset: 51 samples, distribution: {0: 17, 1: 34}\n",
      "1-shot dataset: 2 samples, distribution: {0: 1, 1: 1}\n",
      "3-shot dataset: 6 samples, distribution: {0: 3, 1: 3}\n",
      "5-shot dataset: 10 samples, distribution: {0: 5, 1: 5}\n",
      "10-shot dataset: 20 samples, distribution: {0: 10, 1: 10}\n",
      "17-shot dataset: 34 samples, distribution: {0: 17, 1: 17}\n",
      "\n",
      "\n",
      "==== Training Specialized Models for Imbalanced Data ====\n",
      "\n",
      "Training Balanced Random Forest (full)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rittique/Python_Projects/Filled_Pause_detection/venv/lib/python3.11/site-packages/imblearn/ensemble/_forest.py:601: FutureWarning: The default of `bootstrap` will change from `True` to `False` in version 0.13. This change will follow the implementation proposed in the original paper. Set to `False` to silence this warning and adopt the future behaviour.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'evaluate_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 137\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;66;03m# Run the main script\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 17\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Train specialized models for imbalanced data with full dataset\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Training Specialized Models for Imbalanced Data ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m imbalanced_models \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_balanced_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfull\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Train regular models with the undersampled balanced dataset\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m==== Training with Undersampled Balanced Dataset ====\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 22\u001b[0m, in \u001b[0;36mtrain_balanced_models\u001b[0;34m(X_train, y_train, X_test, y_test, shot_config)\u001b[0m\n\u001b[1;32m     14\u001b[0m brf \u001b[38;5;241m=\u001b[39m BalancedRandomForestClassifier(\n\u001b[1;32m     15\u001b[0m     n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m     16\u001b[0m     replacement\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     17\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     21\u001b[0m brf\u001b[38;5;241m.\u001b[39mfit(X_train_2d, y_train)\n\u001b[0;32m---> 22\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model\u001b[49m(brf, X_test_2d, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalancedRF\u001b[39m\u001b[38;5;124m'\u001b[39m, shot_config)\n\u001b[1;32m     23\u001b[0m all_results\u001b[38;5;241m.\u001b[39mappend(results)\n\u001b[1;32m     24\u001b[0m plot_confusion_matrix(results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfusion_matrix\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBalancedRF\u001b[39m\u001b[38;5;124m'\u001b[39m, shot_config)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluate_model' is not defined"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    \"\"\"Main execution script to train and evaluate all models for filled pause detection\"\"\"\n",
    "    print(\"Starting filled pause detection model evaluation with imbalanced data handling...\")\n",
    "    \n",
    "    # Analyze data imbalance\n",
    "    print(\"\\nData distribution analysis:\")\n",
    "    class_counts = Counter(y)\n",
    "    total_samples = len(y)\n",
    "    for label, count in class_counts.items():\n",
    "        print(f\"Class {label} ({'Field pause' if label == 0 else 'Filled pause'}): {count} samples ({count/total_samples*100:.2f}%)\")\n",
    "    \n",
    "    # Create balanced datasets\n",
    "    balanced_datasets = create_balanced_datasets(X_train, y_train, X_test, y_test)\n",
    "    \n",
    "    # Train specialized models for imbalanced data with full dataset\n",
    "    print(\"\\n\\n==== Training Specialized Models for Imbalanced Data ====\")\n",
    "    imbalanced_models = train_balanced_models(X_train, y_train, X_test, y_test, \"full\")\n",
    "    \n",
    "    # Train regular models with the undersampled balanced dataset\n",
    "    print(\"\\n\\n==== Training with Undersampled Balanced Dataset ====\")\n",
    "    X_balanced, y_balanced = balanced_datasets['undersampled']\n",
    "    \n",
    "    # Statistical Methods\n",
    "    gmm_models, _ = train_gmm(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    hmm_models, _ = train_hmm(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    \n",
    "    # Machine Learning Models\n",
    "    knn_model, _ = train_knn(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    rf_model, _ = train_rf_rfe(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    svm_model, _ = train_svm(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    \n",
    "    # Deep Learning Models\n",
    "    mlp_model, _ = train_mlp(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    cnn_model, _ = train_cnn(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    cnn_xgb_model, _ = train_cnn_xgboost(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    lstm_model, _ = train_lstm(X_balanced, y_balanced, X_test, y_test, \"balanced\")\n",
    "    \n",
    "    # Train models with few-shot learning\n",
    "    for shot_config, (X_few, y_few) in balanced_datasets.items():\n",
    "        if shot_config == 'undersampled' or int(shot_config.split('-')[0]) < 3:\n",
    "            continue  # Skip undersampled and very small datasets\n",
    "            \n",
    "        print(f\"\\n\\n==== Training with {shot_config} Learning ====\")\n",
    "        \n",
    "        # Machine Learning Models - these can work with small datasets\n",
    "        train_knn(X_few, y_few, X_test, y_test, shot_config)\n",
    "        train_rf_rfe(X_few, y_few, X_test, y_test, shot_config)\n",
    "        train_svm(X_few, y_few, X_test, y_test, shot_config)\n",
    "        \n",
    "        # Only train these with more data\n",
    "        if int(shot_config.split('-')[0]) >= 5:\n",
    "            train_gmm(X_few, y_few, X_test, y_test, shot_config)\n",
    "            train_balanced_models(X_few, y_few, X_test, y_test, shot_config)\n",
    "            train_mlp(X_few, y_few, X_test, y_test, shot_config)\n",
    "            train_cnn(X_few, y_few, X_test, y_test, shot_config)\n",
    "            train_lstm(X_few, y_few, X_test, y_test, shot_config)\n",
    "    \n",
    "    # Create results table\n",
    "    results_df = create_results_table()\n",
    "    \n",
    "    # Identify best model based on F1 score\n",
    "    best_result = results_df.loc[results_df['f1_score'].idxmax()]\n",
    "    best_model_name = best_result['model_name']\n",
    "    print(f\"\\nBest model: {best_model_name} with F1 score: {best_result['f1_score']:.4f}\")\n",
    "    \n",
    "    # Apply explainable AI to the best model\n",
    "    model_type, shot_config = best_model_name.split('_', 1)\n",
    "    \n",
    "    # Get the model object\n",
    "    model_key = best_model_name\n",
    "    if model_key in best_models:\n",
    "        model_info = best_models[model_key]\n",
    "        apply_xai_to_model(model_info, X_test, y_test, model_type, shot_config)\n",
    "    \n",
    "    # Additional analysis for top models\n",
    "    print(\"\\n\\n==== Detailed Analysis of Top Models ====\")\n",
    "    top_models = results_df.head(3)['model_name'].values\n",
    "    \n",
    "    for model_name in top_models:\n",
    "        model_type, shot_config = model_name.split('_', 1)\n",
    "        \n",
    "        # Get the corresponding model\n",
    "        if model_name in best_models:\n",
    "            model = best_models[model_name]\n",
    "            \n",
    "            # Perform threshold analysis if the model supports probabilities\n",
    "            if isinstance(model, dict) and 'model' in model and hasattr(model['model'], 'predict_proba'):\n",
    "                print(f\"\\nThreshold analysis for {model_name}:\")\n",
    "                X_test_reshaped = X_test.reshape(X_test.shape[0], -1) if len(X_test.shape) > 2 else X_test\n",
    "                \n",
    "                if 'scaler' in model:\n",
    "                    X_test_scaled = model['scaler'].transform(X_test_reshaped)\n",
    "                    y_prob = model['model'].predict_proba(X_test_scaled)[:, 1]\n",
    "                else:\n",
    "                    y_prob = model['model'].predict_proba(X_test_reshaped)[:, 1]\n",
    "                \n",
    "                # Test different thresholds\n",
    "                thresholds = np.arange(0.1, 1.0, 0.1)\n",
    "                threshold_results = []\n",
    "                \n",
    "                for threshold in thresholds:\n",
    "                    y_pred = (y_prob >= threshold).astype(int)\n",
    "                    precision = precision_score(y_test, y_pred)\n",
    "                    recall = recall_score(y_test, y_pred)\n",
    "                    f1 = f1_score(y_test, y_pred)\n",
    "                    \n",
    "                    threshold_results.append({\n",
    "                        'threshold': threshold,\n",
    "                        'precision': precision,\n",
    "                        'recall': recall,\n",
    "                        'f1_score': f1\n",
    "                    })\n",
    "                \n",
    "                # Convert to DataFrame and plot\n",
    "                threshold_df = pd.DataFrame(threshold_results)\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                plt.plot(threshold_df['threshold'], threshold_df['precision'], 'b-', label='Precision')\n",
    "                plt.plot(threshold_df['threshold'], threshold_df['recall'], 'g-', label='Recall')\n",
    "                plt.plot(threshold_df['threshold'], threshold_df['f1_score'], 'r-', label='F1 Score')\n",
    "                plt.xlabel('Threshold')\n",
    "                plt.ylabel('Score')\n",
    "                plt.title(f'Threshold vs. Metrics for {model_name}')\n",
    "                plt.legend()\n",
    "                plt.grid(True)\n",
    "                plt.savefig(f'results/plots/threshold_analysis_{model_name}.png')\n",
    "                plt.close()\n",
    "    \n",
    "    # Save all results and models\n",
    "    with open('results/tables/all_results.pkl', 'wb') as f:\n",
    "        pickle.dump(all_results, f)\n",
    "    \n",
    "    print(\"\\nFilled pause detection model evaluation completed!\")\n",
    "    print(f\"Results saved to 'results/tables/' and 'results/plots/' directories\")\n",
    "\n",
    "# Run the main script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62b2600-36cf-4718-befb-d7002904faab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv_filled_pause)",
   "language": "python",
   "name": "venv_filled_pause"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
