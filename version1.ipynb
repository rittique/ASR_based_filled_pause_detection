{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0814ec70-9237-4e15-a815-0c15d0014b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Voice 002 (2).m4a to wav_files/Voice 002 (2).wav\n",
      "Converted English 1st conversation.m4a to wav_files/English 1st conversation.wav\n",
      "Converted progga.m4a to wav_files/progga.wav\n",
      "Converted keralas calture.mp3 to wav_files/keralas calture.wav\n",
      "Converted SS practice.mp3 to wav_files/SS practice.wav\n",
      "Converted R10.m4a to wav_files/R10.wav\n",
      "Converted Oct hhjh.mp3 to wav_files/Oct hhjh.wav\n",
      "Converted Voice 001_sd.m4a to wav_files/Voice 001_sd.wav\n",
      "Converted 2024-02-27 21-05-26.mkv to wav_files/2024-02-27 21-05-26.wav\n",
      "Converted cricket toppic.m4a to wav_files/cricket toppic.wav\n",
      "Converted Voice 002.m4a to wav_files/Voice 002.wav\n",
      "Converted sanjid meyad.mp3 to wav_files/sanjid meyad.wav\n",
      "Converted R7.m4a to wav_files/R7.wav\n",
      "Converted Voice 003.m4a to wav_files/Voice 003.wav\n",
      "Converted tamanna.m4a to wav_files/tamanna.wav\n",
      "Converted Voice 001 (2).m4a to wav_files/Voice 001 (2).wav\n",
      "Converted Voice 001.m4a to wav_files/Voice 001.wav\n",
      "Converted Oct 7, 9.34 AM.mp3 to wav_files/Oct 7, 9.34 AM.wav\n",
      "Converted Voice 009_sd.m4a to wav_files/Voice 009_sd.wav\n",
      "Converted Voice 004.m4a to wav_files/Voice 004.wav\n",
      "Converted Voice 007_sd.m4a to wav_files/Voice 007_sd.wav\n",
      "Converted Voice 007.m4a to wav_files/Voice 007.wav\n",
      "Converted Oct 6, 9.10 AM.mp3 to wav_files/Oct 6, 9.10 AM.wav\n",
      "Converted Sep 23, 9.24 AM.mp3 to wav_files/Sep 23, 9.24 AM.wav\n",
      "Converted Voice 006.m4a to wav_files/Voice 006.wav\n",
      "Converted Voice 001_sd (1).m4a to wav_files/Voice 001_sd (1).wav\n",
      "Converted Mirpur Road-1.m4a to wav_files/Mirpur Road-1.wav\n",
      "Converted omg dj.mp3 to wav_files/omg dj.wav\n",
      "Converted R1.mp3 to wav_files/R1.wav\n",
      "Converted Recording_2.m4a to wav_files/Recording_2.wav\n",
      "Converted hjjjhhggh.mp3 to wav_files/hjjjhhggh.wav\n",
      "Converted R2.mp3 to wav_files/R2.wav\n",
      "Converted Recording_1.m4a to wav_files/Recording_1.wav\n",
      "Converted Sep 25, 1.56 sa.mp3 to wav_files/Sep 25, 1.56 sa.wav\n",
      "Converted R3.mp3 to wav_files/R3.wav\n",
      "Converted practice .mp3 to wav_files/practice .wav\n",
      "Converted Voice 010_sd.m4a to wav_files/Voice 010_sd.wav\n",
      "Converted Voice 001 (1).m4a to wav_files/Voice 001 (1).wav\n",
      "Converted Sep 26, 1.30 PM.mp3 to wav_files/Sep 26, 1.30 PM.wav\n",
      "Converted R8.m4a to wav_files/R8.wav\n",
      "Converted Oct 8, 1.45 PM.mp3 to wav_files/Oct 8, 1.45 PM.wav\n",
      "Converted R9.m4a to wav_files/R9.wav\n",
      "Converted the scientist.m4a to wav_files/the scientist.wav\n",
      "Converted Account.mp4 to wav_files/Account.wav\n",
      "Converted R4.mp3 to wav_files/R4.wav\n",
      "Converted R5.mp3 to wav_files/R5.wav\n",
      "Converted Voice 008_sd.m4a to wav_files/Voice 008_sd.wav\n",
      "Converted Recode.m4a to wav_files/Recode.wav\n",
      "Converted New Recording 6.m4a to wav_files/New Recording 6.wav\n",
      "Converted summery.m4a to wav_files/summery.wav\n",
      "Converted kerala.mp3 to wav_files/kerala.wav\n",
      "Converted REC005.mp3 to wav_files/REC005.wav\n",
      "Converted Oct 20, 12.28 PM.mp3 to wav_files/Oct 20, 12.28 PM.wav\n",
      "Converted Voice 002 (1).m4a to wav_files/Voice 002 (1).wav\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Define the input directory containing audio files and output directory\n",
    "input_directory = 'data'  # Change this to your input directory\n",
    "output_directory = 'wav_files'\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "if not os.path.exists(output_directory):\n",
    "    os.makedirs(output_directory)\n",
    "\n",
    "# Convert all audio files in the input directory to WAV format\n",
    "for filename in os.listdir(input_directory):\n",
    "    if filename.endswith(('.mp4', '.mp3', '.ogg', '.flac', '.m4a', '.wma', '.mkv')):  # Add other formats as needed\n",
    "        file_path = os.path.join(input_directory, filename)\n",
    "        try:\n",
    "            # Load the audio file\n",
    "            audio = AudioSegment.from_file(file_path)\n",
    "            # Define output file path\n",
    "            output_file_path = os.path.join(output_directory, f\"{os.path.splitext(filename)[0]}.wav\")\n",
    "            # Export as WAV\n",
    "            audio.export(output_file_path, format='wav')\n",
    "            print(f\"Converted {filename} to {output_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to convert {filename}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70319a18-d1e1-450c-8a9b-401341c91510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cricket toppic': ('JSON/cricket toppic.json', 'wav_files/cricket toppic.wav'), 'R1': ('JSON/R1.json', 'wav_files/R1.wav'), 'New Recording 6': ('JSON/New Recording 6.json', 'wav_files/New Recording 6.wav'), 'Mirpur Road': ('JSON/Mirpur Road.json', 'wav_files/Mirpur Road.wav'), 'Recording_1': ('JSON/Recording_1.json', 'wav_files/Recording_1.wav'), 'Oct 7, 9.34 AM': ('JSON/Oct 7, 9.34 AM.json', 'wav_files/Oct 7, 9.34 AM.wav'), 'keralas calture': ('JSON/keralas calture.json', 'wav_files/keralas calture.wav'), 'the scientist': ('JSON/the scientist.json', 'wav_files/the scientist.wav'), 'Recording_2': ('JSON/Recording_2.json', 'wav_files/Recording_2.wav'), 'R5': ('JSON/R5.json', 'wav_files/R5.wav'), 'Sep 23, 9.24 AM': ('JSON/Sep 23, 9.24 AM.json', 'wav_files/Sep 23, 9.24 AM.wav'), 'English 1st conversation': ('JSON/English 1st conversation.json', 'wav_files/English 1st conversation.wav'), 'SS practice': ('JSON/SS practice.json', 'wav_files/SS practice.wav'), 'sanjid meyad': ('JSON/sanjid meyad.json', 'wav_files/sanjid meyad.wav'), 'Sep 25, 1.56 sa': ('JSON/Sep 25, 1.56 sa.json', 'wav_files/Sep 25, 1.56 sa.wav'), 'Oct 20, 12.28 PM': ('JSON/Oct 20, 12.28 PM.json', 'wav_files/Oct 20, 12.28 PM.wav'), 'Oct 6, 9.10 AM': ('JSON/Oct 6, 9.10 AM.json', 'wav_files/Oct 6, 9.10 AM.wav'), 'R2': ('JSON/R2.json', 'wav_files/R2.wav')}\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths to JSON and audio files\n",
    "json_folder = 'JSON'\n",
    "audio_folder = 'wav_files'\n",
    "\n",
    "# Match audio and JSON files\n",
    "json_files = {os.path.splitext(f)[0]: os.path.join(json_folder, f) for f in os.listdir(json_folder) if f.endswith('.json')}\n",
    "audio_files = {os.path.splitext(f)[0]: os.path.join(audio_folder, f) for f in os.listdir(audio_folder) if f.endswith(('.wav', '.m4a', '.mp3'))}\n",
    "\n",
    "matched_files = {name: (json_files[name], audio_files[name]) for name in json_files if name in audio_files}\n",
    "\n",
    "print(matched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0dcdbc5-30e8-4d7b-9406-80ea2b858e5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(matched_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "305ada80-a5ed-4f8a-996c-ec27c979a9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_annotations(json_file):\n",
    "    with open(json_file, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    annotations = []\n",
    "    for item in data[0]['annotations'][0]['result']:\n",
    "        if item['type'] == 'labels':\n",
    "            start = item['value']['start']\n",
    "            end = item['value']['end']\n",
    "            label = item['value']['labels'][0]\n",
    "            annotations.append((start, end, label))\n",
    "    return annotations\n",
    "\n",
    "def extract_audio_segments(audio_file, annotations, sr=16000):\n",
    "    y, _ = librosa.load(audio_file, sr=sr)\n",
    "    segments = []\n",
    "    for start, end, label in annotations:\n",
    "        segment = y[int(start * sr):int(end * sr)]\n",
    "        segments.append((segment, label))\n",
    "    return segments\n",
    "\n",
    "dataset = []\n",
    "files_loaded = []\n",
    "\n",
    "for name, (json_path, audio_path) in matched_files.items():\n",
    "    if len(load_annotations(json_path)) != 0:\n",
    "        files_loaded.append(json_path)\n",
    "        annotations = load_annotations(json_path)\n",
    "        audio_segments = extract_audio_segments(audio_path, annotations)\n",
    "        dataset.extend(audio_segments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d417016-cbe0-44ff-a328-963a503b2fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['JSON/cricket toppic.json', 'JSON/R1.json', 'JSON/New Recording 6.json', 'JSON/Mirpur Road.json', 'JSON/Recording_1.json', 'JSON/Oct 7, 9.34 AM.json', 'JSON/keralas calture.json', 'JSON/the scientist.json', 'JSON/Recording_2.json', 'JSON/R5.json', 'JSON/Sep 23, 9.24 AM.json', 'JSON/English 1st conversation.json', 'JSON/SS practice.json', 'JSON/sanjid meyad.json', 'JSON/Sep 25, 1.56 sa.json', 'JSON/Oct 20, 12.28 PM.json', 'JSON/Oct 6, 9.10 AM.json', 'JSON/R2.json']\n"
     ]
    }
   ],
   "source": [
    "print(files_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "199929e4-85d3-4323-98e8-4221a0ced21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(segments, n_mfcc=40, max_length=300):\n",
    "    features, labels = [], []\n",
    "    for i, (segment, label) in enumerate(segments):\n",
    "        try:\n",
    "            # Dynamically adjust n_fft based on signal length\n",
    "            n_fft = min(2048, len(segment))  # Use the smaller of 2048 or segment length\n",
    "\n",
    "            # Extract MFCC features with adjusted n_fft\n",
    "            mfcc = librosa.feature.mfcc(y=segment, sr=16000, n_mfcc=n_mfcc, n_fft=n_fft)\n",
    "\n",
    "            # Handle variable lengths (pad if short, truncate if long)\n",
    "            if mfcc.shape[1] < max_length:\n",
    "                padded_mfcc = np.pad(mfcc, ((0, 0), (0, max_length - mfcc.shape[1])), mode='constant')\n",
    "            else:\n",
    "                padded_mfcc = mfcc[:, :max_length]\n",
    "\n",
    "            # Append features and labels\n",
    "            features.append(padded_mfcc.T)\n",
    "            labels.append(0 if label == 'Field pause' else 1)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing segment {i}: {e}\")\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "X, y = extract_features(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29fa9d63-15ed-4bea-89b7-287e2f151cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">41,768</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentio…</span> │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">10,408</span> │ layer_normalizat… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ sequential[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
       "│                     │                   │            │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">82</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalization │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │         \u001b[38;5;34m80\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ multi_head_attenti… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m41,768\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mMultiHeadAttentio…\u001b[0m │                   │            │ layer_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ multi_head_atten… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ layer_normalizatio… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │         \u001b[38;5;34m80\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "│ (\u001b[38;5;33mLayerNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ sequential          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │     \u001b[38;5;34m10,408\u001b[0m │ layer_normalizat… │\n",
       "│ (\u001b[38;5;33mSequential\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m, \u001b[38;5;34m40\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ sequential[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
       "│                     │                   │            │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)         │         \u001b[38;5;34m82\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,418</span> (204.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m52,418\u001b[0m (204.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">52,418</span> (204.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m52,418\u001b[0m (204.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, LayerNormalization, MultiHeadAttention, Dropout, GlobalAveragePooling1D\n",
    "\n",
    "def transformer_block(inputs, head_size, num_heads, ff_dim, dropout_rate=0.1):\n",
    "    x = LayerNormalization(epsilon=1e-6)(inputs)\n",
    "    x = MultiHeadAttention(num_heads=num_heads, key_dim=head_size, dropout=dropout_rate)(x, x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = LayerNormalization(epsilon=1e-6)(res)\n",
    "    x = tf.keras.Sequential([\n",
    "        Dense(ff_dim, activation=\"relu\"),\n",
    "        Dense(inputs.shape[-1]),\n",
    "    ])(x)\n",
    "    return x + res\n",
    "\n",
    "\n",
    "def build_transformer_model(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = transformer_block(inputs, head_size=64, num_heads=4, ff_dim=128)\n",
    "    x = GlobalAveragePooling1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    outputs = Dense(num_classes, activation=\"softmax\")(x)\n",
    "    return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "model = build_transformer_model(input_shape=(300, 40), num_classes=2)\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dad63179-653a-4d2d-91ec-17d11312aecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.5662 - loss: 6.3593 - val_accuracy: 0.9860 - val_loss: 0.2257\n",
      "Epoch 2/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 295ms/step - accuracy: 0.9570 - loss: 0.7558 - val_accuracy: 0.9895 - val_loss: 0.1298\n",
      "Epoch 3/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 389ms/step - accuracy: 0.9741 - loss: 0.4910 - val_accuracy: 0.9895 - val_loss: 0.0986\n",
      "Epoch 4/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 327ms/step - accuracy: 0.9645 - loss: 0.4075 - val_accuracy: 0.9895 - val_loss: 0.0768\n",
      "Epoch 5/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 301ms/step - accuracy: 0.9768 - loss: 0.1716 - val_accuracy: 0.9895 - val_loss: 0.0614\n",
      "Epoch 6/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 281ms/step - accuracy: 0.9764 - loss: 0.1952 - val_accuracy: 0.9895 - val_loss: 0.0684\n",
      "Epoch 7/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 282ms/step - accuracy: 0.9726 - loss: 0.2538 - val_accuracy: 0.9895 - val_loss: 0.0460\n",
      "Epoch 8/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9753 - loss: 0.2475 - val_accuracy: 0.9895 - val_loss: 0.0483\n",
      "Epoch 9/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 290ms/step - accuracy: 0.9734 - loss: 0.1776 - val_accuracy: 0.9789 - val_loss: 0.0500\n",
      "Epoch 10/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 275ms/step - accuracy: 0.9646 - loss: 0.1406 - val_accuracy: 0.9930 - val_loss: 0.0375\n",
      "Epoch 11/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9777 - loss: 0.1755 - val_accuracy: 0.9930 - val_loss: 0.0337\n",
      "Epoch 12/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9719 - loss: 0.2155 - val_accuracy: 0.9930 - val_loss: 0.0400\n",
      "Epoch 13/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9721 - loss: 0.1578 - val_accuracy: 0.9930 - val_loss: 0.0341\n",
      "Epoch 14/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 286ms/step - accuracy: 0.9835 - loss: 0.2071 - val_accuracy: 0.9930 - val_loss: 0.0373\n",
      "Epoch 15/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9731 - loss: 0.1543 - val_accuracy: 0.9895 - val_loss: 0.0330\n",
      "Epoch 16/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9783 - loss: 0.1633 - val_accuracy: 0.9930 - val_loss: 0.0345\n",
      "Epoch 17/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9861 - loss: 0.0818 - val_accuracy: 0.9860 - val_loss: 0.0361\n",
      "Epoch 18/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 279ms/step - accuracy: 0.9817 - loss: 0.0880 - val_accuracy: 0.9895 - val_loss: 0.0305\n",
      "Epoch 19/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 270ms/step - accuracy: 0.9718 - loss: 0.1201 - val_accuracy: 0.9930 - val_loss: 0.0433\n",
      "Epoch 20/20\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 273ms/step - accuracy: 0.9685 - loss: 0.1886 - val_accuracy: 0.9930 - val_loss: 0.0438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x35d7b2910>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41f45230-e987-45ea-abc0-9dfa17877540",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 284ms/step - accuracy: 0.9780 - loss: 0.1399 - val_accuracy: 0.9930 - val_loss: 0.0261\n",
      "Epoch 2/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 288ms/step - accuracy: 0.9871 - loss: 0.0736 - val_accuracy: 0.9860 - val_loss: 0.0342\n",
      "Epoch 3/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 277ms/step - accuracy: 0.9854 - loss: 0.0707 - val_accuracy: 0.9895 - val_loss: 0.0364\n",
      "Epoch 4/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 272ms/step - accuracy: 0.9873 - loss: 0.0606 - val_accuracy: 0.9860 - val_loss: 0.0373\n",
      "Epoch 5/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 274ms/step - accuracy: 0.9881 - loss: 0.0532 - val_accuracy: 0.9895 - val_loss: 0.0262\n",
      "Epoch 6/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 382ms/step - accuracy: 0.9846 - loss: 0.0891 - val_accuracy: 0.9860 - val_loss: 0.0366\n",
      "Epoch 7/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 360ms/step - accuracy: 0.9894 - loss: 0.0755 - val_accuracy: 0.9895 - val_loss: 0.0352\n",
      "Epoch 8/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 324ms/step - accuracy: 0.9951 - loss: 0.0178 - val_accuracy: 0.9825 - val_loss: 0.0337\n",
      "Epoch 9/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 323ms/step - accuracy: 0.9911 - loss: 0.0585 - val_accuracy: 0.9895 - val_loss: 0.0369\n",
      "Epoch 10/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 354ms/step - accuracy: 0.9894 - loss: 0.0347 - val_accuracy: 0.9930 - val_loss: 0.0425\n",
      "Epoch 11/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 327ms/step - accuracy: 0.9920 - loss: 0.0293 - val_accuracy: 0.9825 - val_loss: 0.0431\n",
      "Epoch 12/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 301ms/step - accuracy: 0.9925 - loss: 0.0431 - val_accuracy: 0.9684 - val_loss: 0.0753\n",
      "Epoch 13/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 353ms/step - accuracy: 0.9882 - loss: 0.0375 - val_accuracy: 0.9895 - val_loss: 0.0395\n",
      "Epoch 14/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 291ms/step - accuracy: 0.9925 - loss: 0.0337 - val_accuracy: 0.9895 - val_loss: 0.0494\n",
      "Epoch 15/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 280ms/step - accuracy: 0.9904 - loss: 0.0396 - val_accuracy: 0.9754 - val_loss: 0.0595\n",
      "Epoch 16/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 300ms/step - accuracy: 0.9917 - loss: 0.0445 - val_accuracy: 0.9895 - val_loss: 0.0314\n",
      "Epoch 17/17\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 309ms/step - accuracy: 0.9925 - loss: 0.0349 - val_accuracy: 0.9895 - val_loss: 0.0550\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x365fc6010>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32, epochs=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7642e6d-0772-4b82-a51d-5b5c98f92801",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1625a92-6521-4e7a-94be-5fd428acb1ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (996, 300, 40), (996,)\n",
      "Validation set: (213, 300, 40), (213,)\n",
      "Test set: (214, 300, 40), (214,)\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42, stratify=y_temp)\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c0e0e57-3932-4b97-8572-e5b774a6a0df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random combinations to test: 50\n",
      "Trial 1/50: Testing parameters: {'batch_size': 64, 'epochs': 30, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 64, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/keras/src/ops/nn.py:827: UserWarning: You are using a softmax over axis -1 of a tensor of shape (None, 1). This axis has size 1. The softmax operation will always return the value 1, which is likely not what you intended. Did you mean to use a sigmoid instead?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.9859\n",
      "Trial 2/50: Testing parameters: {'batch_size': 25, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 3/50: Testing parameters: {'batch_size': 32, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 64, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 4/50: Testing parameters: {'batch_size': 64, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 2, 'ff_dim': 64, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 5/50: Testing parameters: {'batch_size': 17, 'epochs': 30, 'learning_rate': 0.1, 'dropout_rate': 0.01, 'head_size': 64, 'num_heads': 4, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 6/50: Testing parameters: {'batch_size': 32, 'epochs': 30, 'learning_rate': 0.01, 'dropout_rate': 0.01, 'head_size': 64, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 7/50: Testing parameters: {'batch_size': 17, 'epochs': 10, 'learning_rate': 0.0001, 'dropout_rate': 0.3, 'head_size': 128, 'num_heads': 8, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 8/50: Testing parameters: {'batch_size': 64, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 9/50: Testing parameters: {'batch_size': 17, 'epochs': 30, 'learning_rate': 0.01, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 10/50: Testing parameters: {'batch_size': 20, 'epochs': 30, 'learning_rate': 0.1, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 2, 'ff_dim': 64, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9812\n",
      "Trial 11/50: Testing parameters: {'batch_size': 32, 'epochs': 10, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 64, 'num_heads': 4, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 12/50: Testing parameters: {'batch_size': 17, 'epochs': 10, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 32, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 13/50: Testing parameters: {'batch_size': 10, 'epochs': 10, 'learning_rate': 0.1, 'dropout_rate': 0.1, 'head_size': 64, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 14/50: Testing parameters: {'batch_size': 25, 'epochs': 50, 'learning_rate': 0.1, 'dropout_rate': 0.1, 'head_size': 64, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 15/50: Testing parameters: {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 64, 'num_heads': 2, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 16/50: Testing parameters: {'batch_size': 25, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.5, 'head_size': 64, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 17/50: Testing parameters: {'batch_size': 25, 'epochs': 10, 'learning_rate': 0.0001, 'dropout_rate': 0.5, 'head_size': 128, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 18/50: Testing parameters: {'batch_size': 10, 'epochs': 10, 'learning_rate': 0.01, 'dropout_rate': 0.01, 'head_size': 32, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 19/50: Testing parameters: {'batch_size': 20, 'epochs': 10, 'learning_rate': 0.001, 'dropout_rate': 0.1, 'head_size': 64, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 20/50: Testing parameters: {'batch_size': 25, 'epochs': 50, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 8, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 21/50: Testing parameters: {'batch_size': 20, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 32, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9906\n",
      "Trial 22/50: Testing parameters: {'batch_size': 32, 'epochs': 30, 'learning_rate': 0.0001, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 23/50: Testing parameters: {'batch_size': 20, 'epochs': 40, 'learning_rate': 0.0001, 'dropout_rate': 0.5, 'head_size': 128, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 24/50: Testing parameters: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.1, 'dropout_rate': 0.01, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9718\n",
      "Trial 25/50: Testing parameters: {'batch_size': 17, 'epochs': 30, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 26/50: Testing parameters: {'batch_size': 10, 'epochs': 30, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9906\n",
      "Trial 27/50: Testing parameters: {'batch_size': 64, 'epochs': 20, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'head_size': 128, 'num_heads': 4, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 28/50: Testing parameters: {'batch_size': 25, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 32, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 29/50: Testing parameters: {'batch_size': 17, 'epochs': 10, 'learning_rate': 0.0001, 'dropout_rate': 0.01, 'head_size': 64, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 30/50: Testing parameters: {'batch_size': 10, 'epochs': 50, 'learning_rate': 0.1, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 31/50: Testing parameters: {'batch_size': 25, 'epochs': 30, 'learning_rate': 0.1, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 32/50: Testing parameters: {'batch_size': 32, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 33/50: Testing parameters: {'batch_size': 25, 'epochs': 50, 'learning_rate': 0.1, 'dropout_rate': 0.5, 'head_size': 128, 'num_heads': 4, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 34/50: Testing parameters: {'batch_size': 20, 'epochs': 50, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'head_size': 64, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 35/50: Testing parameters: {'batch_size': 20, 'epochs': 10, 'learning_rate': 0.001, 'dropout_rate': 0.01, 'head_size': 32, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 36/50: Testing parameters: {'batch_size': 20, 'epochs': 10, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 4, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 37/50: Testing parameters: {'batch_size': 20, 'epochs': 10, 'learning_rate': 0.1, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 4, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 38/50: Testing parameters: {'batch_size': 32, 'epochs': 40, 'learning_rate': 0.1, 'dropout_rate': 0.5, 'head_size': 64, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9765\n",
      "Trial 39/50: Testing parameters: {'batch_size': 64, 'epochs': 10, 'learning_rate': 0.1, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 40/50: Testing parameters: {'batch_size': 64, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.01, 'head_size': 128, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 41/50: Testing parameters: {'batch_size': 64, 'epochs': 30, 'learning_rate': 0.01, 'dropout_rate': 0.3, 'head_size': 128, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 42/50: Testing parameters: {'batch_size': 64, 'epochs': 50, 'learning_rate': 0.001, 'dropout_rate': 0.1, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'hinge', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 43/50: Testing parameters: {'batch_size': 32, 'epochs': 50, 'learning_rate': 0.001, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 4, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9906\n",
      "Trial 44/50: Testing parameters: {'batch_size': 10, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 4, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 45/50: Testing parameters: {'batch_size': 20, 'epochs': 30, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 2, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9765\n",
      "Trial 46/50: Testing parameters: {'batch_size': 25, 'epochs': 10, 'learning_rate': 0.01, 'dropout_rate': 0.5, 'head_size': 32, 'num_heads': 2, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 47/50: Testing parameters: {'batch_size': 32, 'epochs': 30, 'learning_rate': 0.001, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 4, 'ff_dim': 64, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Validation Accuracy: 0.9906\n",
      "Trial 48/50: Testing parameters: {'batch_size': 25, 'epochs': 50, 'learning_rate': 0.1, 'dropout_rate': 0.3, 'head_size': 32, 'num_heads': 8, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 49/50: Testing parameters: {'batch_size': 10, 'epochs': 40, 'learning_rate': 0.1, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 4, 'ff_dim': 128, 'loss_function': 'binary_crossentropy', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Trial 50/50: Testing parameters: {'batch_size': 17, 'epochs': 10, 'learning_rate': 0.1, 'dropout_rate': 0.1, 'head_size': 128, 'num_heads': 2, 'ff_dim': 64, 'loss_function': 'hinge', 'activation_function': 'softmax'}\n",
      "Validation Accuracy: 0.9859\n",
      "Best hyperparameters: {'batch_size': 20, 'epochs': 20, 'learning_rate': 0.0001, 'dropout_rate': 0.1, 'head_size': 32, 'num_heads': 8, 'ff_dim': 256, 'loss_function': 'binary_crossentropy', 'activation_function': 'sigmoid'}\n",
      "Best validation accuracy: 0.9906103014945984\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define hyperparameter ranges\n",
    "param_grid = {\n",
    "    'batch_size': [10, 17, 20, 25, 32, 64],                    # Batch sizes\n",
    "    'epochs': [10, 20, 30, 40, 50],                           # Epoch counts\n",
    "    'learning_rate': [1e-4, 1e-3, 1e-2, 1e-1],                # Learning rates\n",
    "    'dropout_rate': [0.01, 0.1, 0.3, 0.5],                    # Dropout rates\n",
    "    'head_size': [32, 64, 128],                               # Transformer head sizes\n",
    "    'num_heads': [2, 4, 8],                                   # Number of attention heads\n",
    "    'ff_dim': [64, 128, 256],                                 # Feed-forward dimensions\n",
    "    'loss_function': ['binary_crossentropy', 'hinge'],        # Loss functions\n",
    "    'activation_function': ['sigmoid', 'softmax']             # Output layer activation functions\n",
    "}\n",
    "\n",
    "# Randomly sample combinations\n",
    "n_trials = 50  # Number of random combinations to test\n",
    "random_combinations = [\n",
    "    {key: random.choice(values) for key, values in param_grid.items()}\n",
    "    for _ in range(n_trials)\n",
    "]\n",
    "print(f\"Random combinations to test: {len(random_combinations)}\")\n",
    "\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Perform RandomCV\n",
    "for trial, params in enumerate(random_combinations):\n",
    "    print(f\"Trial {trial + 1}/{len(random_combinations)}: Testing parameters: {params}\")\n",
    "    \n",
    "    # Build model with current hyperparameters\n",
    "    def build_model(input_shape, num_classes, head_size, num_heads, ff_dim, dropout_rate, activation_function):\n",
    "        inputs = Input(shape=input_shape)\n",
    "        x = transformer_block(inputs, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout_rate=dropout_rate)\n",
    "        x = GlobalAveragePooling1D()(x)\n",
    "        x = Dropout(dropout_rate)(x)\n",
    "        outputs = Dense(num_classes, activation=activation_function)(x)  # Dynamic activation\n",
    "        return tf.keras.Model(inputs, outputs)\n",
    "\n",
    "    # Compile model\n",
    "    model = build_model(\n",
    "        input_shape=(300, 40),\n",
    "        num_classes=1,  # Binary classification requires 1 output node\n",
    "        head_size=params['head_size'],\n",
    "        num_heads=params['num_heads'],\n",
    "        ff_dim=params['ff_dim'],\n",
    "        dropout_rate=params['dropout_rate'],\n",
    "        activation_function=params['activation_function']\n",
    "    )\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=params['learning_rate']),\n",
    "                  loss=params['loss_function'],  # Dynamic loss function\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_val, y_val),\n",
    "        batch_size=params['batch_size'],\n",
    "        epochs=params['epochs'],\n",
    "        verbose=0\n",
    "    )\n",
    "\n",
    "    # Evaluate on the validation set\n",
    "    val_loss, val_accuracy = model.evaluate(X_val, y_val, verbose=0)\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    \n",
    "    # Track the best parameters\n",
    "    if val_accuracy > best_accuracy:\n",
    "        best_accuracy = val_accuracy\n",
    "        best_params = params\n",
    "\n",
    "# Output the best hyperparameters\n",
    "print(\"Best hyperparameters:\", best_params)\n",
    "print(\"Best validation accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca0850d5-aa56-40f2-bb6d-cc10a2500eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 201ms/step - accuracy: 0.1790 - loss: 11.9956 - val_accuracy: 0.4038 - val_loss: 9.1917\n",
      "Epoch 2/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 220ms/step - accuracy: 0.5003 - loss: 7.2457 - val_accuracy: 0.5352 - val_loss: 5.4666\n",
      "Epoch 3/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 202ms/step - accuracy: 0.6323 - loss: 4.4953 - val_accuracy: 0.7183 - val_loss: 2.6396\n",
      "Epoch 4/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 213ms/step - accuracy: 0.7852 - loss: 2.3519 - val_accuracy: 0.8779 - val_loss: 1.1509\n",
      "Epoch 5/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 219ms/step - accuracy: 0.8915 - loss: 0.9979 - val_accuracy: 0.9155 - val_loss: 0.5729\n",
      "Epoch 6/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 204ms/step - accuracy: 0.9219 - loss: 0.5200 - val_accuracy: 0.9390 - val_loss: 0.2952\n",
      "Epoch 7/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.9380 - loss: 0.3567 - val_accuracy: 0.9765 - val_loss: 0.1730\n",
      "Epoch 8/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 252ms/step - accuracy: 0.9619 - loss: 0.4052 - val_accuracy: 0.9812 - val_loss: 0.1471\n",
      "Epoch 9/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - accuracy: 0.9587 - loss: 0.3543 - val_accuracy: 0.9859 - val_loss: 0.1326\n",
      "Epoch 10/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 216ms/step - accuracy: 0.9678 - loss: 0.2461 - val_accuracy: 0.9859 - val_loss: 0.1221\n",
      "Epoch 11/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.9790 - loss: 0.1557 - val_accuracy: 0.9859 - val_loss: 0.1103\n",
      "Epoch 12/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 211ms/step - accuracy: 0.9732 - loss: 0.2943 - val_accuracy: 0.9859 - val_loss: 0.0990\n",
      "Epoch 13/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.9761 - loss: 0.1933 - val_accuracy: 0.9859 - val_loss: 0.0932\n",
      "Epoch 14/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.9792 - loss: 0.2035 - val_accuracy: 0.9859 - val_loss: 0.0848\n",
      "Epoch 15/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 234ms/step - accuracy: 0.9688 - loss: 0.1898 - val_accuracy: 0.9859 - val_loss: 0.0782\n",
      "Epoch 16/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 215ms/step - accuracy: 0.9593 - loss: 0.3199 - val_accuracy: 0.9859 - val_loss: 0.0776\n",
      "Epoch 17/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 217ms/step - accuracy: 0.9651 - loss: 0.3056 - val_accuracy: 0.9859 - val_loss: 0.0781\n",
      "Epoch 18/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 229ms/step - accuracy: 0.9724 - loss: 0.2913 - val_accuracy: 0.9859 - val_loss: 0.0760\n",
      "Epoch 19/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.9778 - loss: 0.2214 - val_accuracy: 0.9859 - val_loss: 0.0744\n",
      "Epoch 20/20\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 207ms/step - accuracy: 0.9697 - loss: 0.2223 - val_accuracy: 0.9859 - val_loss: 0.0746\n"
     ]
    }
   ],
   "source": [
    "# Retrieve best hyperparameters\n",
    "batch_size = best_params['batch_size']\n",
    "epochs = best_params['epochs']\n",
    "learning_rate = best_params['learning_rate']\n",
    "dropout_rate = best_params['dropout_rate']\n",
    "\n",
    "# Build the final model\n",
    "final_model = build_transformer_model(input_shape=(300, 40), num_classes=2)\n",
    "final_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                    loss='sparse_categorical_crossentropy',\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "# Train the final model\n",
    "history = final_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f56ed2cc-3e4d-4074-b458-e082a1069655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 136ms/step - accuracy: 0.9843 - loss: 0.1459\n",
      "Test Accuracy: 0.9813\n",
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 109ms/step\n",
      "\n",
      "Classification Report:\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Filled Pause       0.00      0.00      0.00         4\n",
      "Non-Field Pause       0.98      1.00      0.99       210\n",
      "\n",
      "       accuracy                           0.98       214\n",
      "      macro avg       0.49      0.50      0.50       214\n",
      "   weighted avg       0.96      0.98      0.97       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/opt/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x4165d2d50>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on the test set\n",
    "test_loss, test_accuracy = final_model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Generate classification report and confusion matrix\n",
    "y_pred = np.argmax(final_model.predict(X_test), axis=1)\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Filled Pause\", \"Non-Field Pause\"]))\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Filled Pause\", \"Non-Field Pause\"])\n",
    "disp.plot(cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "596876b1-3c11-4cf1-b390-5981629bc829",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as 'filled_pause_detector.h5'\n"
     ]
    }
   ],
   "source": [
    "final_model.save(\"filled_pause_detector.h5\")\n",
    "print(\"Model saved as 'filled_pause_detector.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a5aec2-fa11-4dd8-b874-38e99392f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model\n",
    "loaded_model = tf.keras.models.load_model(\"filled_pause_detector.h5\")\n",
    "print(\"Model loaded successfully!\")\n",
    "\n",
    "# Prepare new input data for prediction\n",
    "def predict_filled_pause(segment):\n",
    "    # Extract MFCC features\n",
    "    mfcc = librosa.feature.mfcc(y=segment, sr=16000, n_mfcc=40)\n",
    "    if mfcc.shape[1] < 300:\n",
    "        padded_mfcc = np.pad(mfcc, ((0, 0), (0, 300 - mfcc.shape[1])), mode='constant')\n",
    "    else:\n",
    "        padded_mfcc = mfcc[:, :300]\n",
    "\n",
    "    # Reshape input for the model\n",
    "    input_data = np.expand_dims(padded_mfcc.T, axis=0)\n",
    "\n",
    "    # Predict\n",
    "    prediction = loaded_model.predict(input_data)\n",
    "    predicted_label = np.argmax(prediction)\n",
    "    return \"Filled Pause\" if predicted_label == 0 else \"Non-Field Pause\"\n",
    "\n",
    "# Example usage\n",
    "segment = X_test[0]  # Replace with your actual audio segment\n",
    "prediction = predict_filled_pause(segment)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f661042-3f49-4719-be7d-0521661e0276",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
